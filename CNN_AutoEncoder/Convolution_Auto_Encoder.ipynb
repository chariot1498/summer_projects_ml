{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#I am going to create an autoencoder using keras and model from keras.model because layers are functions .\n",
    "import keras\n",
    "#we will go through the use of these layers as we use them when they are needed later down.\n",
    "from keras.layers import Convolution2D, Flatten, Dense, MaxPool2D, Activation, Dropout\n",
    "from keras.layers import UpSampling2D, Reshape, ZeroPadding2D, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading from MNIST dataset it is needed to be in the same directory as your script.\n",
    "\n",
    "ds = pd.read_csv('train.csv')\n",
    "ds.shape\n",
    "#I am taking only 10000 examples to make the script run faster you can if you want take all the examples depending on \n",
    "#your computer's processing power.\n",
    "data = ds.values[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#converting range of each pixel from 0 to 1.\n",
    "X = data[:, 1:]/255.0\n",
    "#Converting each y from just the class value(10000,1) to a vector representing 1 for the class it belongs to in(10000,10)\n",
    "y = np_utils.to_categorical(data[:, 0])\n",
    "\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 28, 28, 1) (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Creating training and testing data\n",
    "#We don't need y as we are not predicting.\n",
    "split = int(0.8 * X.shape[0])\n",
    "\n",
    "X_train = X[:split].reshape((-1, 28, 28, 1))\n",
    "X_test = X[split:].reshape((-1, 28, 28, 1))\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e727ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_img = 42\n",
    "#Just printing a random image in the mnist dataset\n",
    "plt.imshow(X_train[n_img].reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 8)         2312      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               6600      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        2336      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         801       \n",
      "=================================================================\n",
      "Total params: 19,313\n",
      "Trainable params: 19,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#To properly see how convolution works or how kernel works please see CNN_MNIST . \n",
    "\n",
    "#We will first apply convolutional layer to take it down to 5,5,8 from 28,28,1 \n",
    "inp = Input(shape=(28, 28, 1))  #This is the input layer\n",
    "\n",
    "#First convolution layer with 32 kernels each of size 5,5 which gives us 24,24,32 i.e. 32 feature maps.\n",
    "\n",
    "c1 = Convolution2D(32, (5, 5))\n",
    "a1 = Activation('relu')\n",
    "\n",
    "#Now we apply maxpool with 2,2 kernel to get 12,12,32 . \n",
    "\n",
    "m1 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "#Second convolution layer with 8 kernels and 3,3 kernel size this gives us 10,10,8 image with 8 feature maps .\n",
    "\n",
    "c2 = Convolution2D(8, (3, 3))\n",
    "a2 = Activation('relu')\n",
    "\n",
    "#Second maxpool with 2,2 kernel to get 5,5,8 .\n",
    "\n",
    "m2 = MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "#It is now flattened to 200 size vector .\n",
    "\n",
    "f1 = Flatten()\n",
    "\n",
    "#emb shape is the final shape of vector you need as the result of encoder i have set it to 32 it is mostly preferable to\n",
    "#be a power of 2 we are using tanh as the activation function to wrap the input from -1 to 1 sigmoid is also good \n",
    "#as the output from it is 0 to 1\n",
    "\n",
    "emb_shape = 32\n",
    "e1 = Dense(emb_shape)\n",
    "emb = Activation('tanh')\n",
    "\n",
    "#We need sigmoid activation as if the input is -1 to 1in case we used tanh the we need it to be in 0 to 1 relu should be\n",
    "#avoided as it will ignore values below 0 .\n",
    "\n",
    "fc1 = Dense(200)\n",
    "a3 = Activation('sigmoid')\n",
    "\n",
    "#Recreating the matrix .\n",
    "\n",
    "re1 = Reshape((5, 5, 8))\n",
    "\n",
    "#We need to do upsampling it is the opposite of maxpool in this every value is put to the 4 cells opposite of maxpool.\n",
    "#we get 10,10,8\n",
    "\n",
    "up1 = UpSampling2D(size=(2, 2))\n",
    "\n",
    "#Now we apply zeropadding (1,1) to get two zero rows and to get 2 zero columns so we end up with 12,12,8\n",
    "\n",
    "zp1 = ZeroPadding2D(padding=(1, 1))\n",
    "\n",
    "#We apply convolution to get 12,12,32 padding = 'true' makes sure that size of the output remains same as the size of \n",
    "#input thus instead of 10,10,32 we get 12,12,32 plus the borders instead of zeroes get some value filled in them .\n",
    "#If we had applied convolution first and the padding then the borders would have remained zero .\n",
    "\n",
    "dc1 = Convolution2D(32, (3, 3), padding='same', activation='relu')\n",
    "\n",
    "#Upsampling is again done to get 24,24,32 .\n",
    "\n",
    "up2 = UpSampling2D(size=(2, 2))\n",
    "\n",
    "#We again repeat the deconvolution step to achieve 28,28,1 which was the original input .\n",
    "\n",
    "zp2 = ZeroPadding2D(padding=(2, 2))\n",
    "dc2 = Convolution2D(1, (5, 5), padding='same', activation='relu')\n",
    "\n",
    "#Now we need to wrap them as fuctions of out_enc (output of encoder) and out_model (output of model).\n",
    "\n",
    "out_enc = emb(e1(f1(m2(a2(c2(m1(a1(c1(inp)))))))))\n",
    "out_model = dc2(zp2(up2(dc1(zp1(up1(re1(a3(fc1(out_enc)))))))))\n",
    "\n",
    "#We finally complete the model building with this step .\n",
    "\n",
    "model = Model(inputs=[inp], outputs=[out_model])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#This is the encoder model compling above model we dont need to complile encoder model.\n",
    "\n",
    "encoder = Model(inputs=[inp], outputs=[out_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 8)         2312      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 9,576\n",
      "Trainable params: 9,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               6600      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        2336      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         801       \n",
      "=================================================================\n",
      "Total params: 9,737\n",
      "Trainable params: 9,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input to decoder .\n",
    "\n",
    "dec_inp = Input(shape=(emb_shape,))\n",
    "\n",
    "dec_out = dc2(zp2(up2(dc1(zp1(up1(re1(a3(fc1(dec_inp)))))))))\n",
    "#Creating the decoder model no need to compile it .\n",
    "decoder = Model(inputs=[dec_inp], outputs=[dec_out])\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 29s - loss: 0.0617 - acc: 0.8017 - val_loss: 0.0447 - val_acc: 0.8007\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 27s - loss: 0.0358 - acc: 0.8030 - val_loss: 0.0308 - val_acc: 0.8040\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 27s - loss: 0.0278 - acc: 0.8067 - val_loss: 0.0260 - val_acc: 0.8039\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 27s - loss: 0.0238 - acc: 0.8085 - val_loss: 0.0225 - val_acc: 0.8066\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 27s - loss: 0.0212 - acc: 0.8095 - val_loss: 0.0204 - val_acc: 0.8077\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 28s - loss: 0.0193 - acc: 0.8101 - val_loss: 0.0193 - val_acc: 0.8091\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 28s - loss: 0.0180 - acc: 0.8106 - val_loss: 0.0177 - val_acc: 0.8083\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 31s - loss: 0.0169 - acc: 0.8109 - val_loss: 0.0170 - val_acc: 0.8096\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 28s - loss: 0.0159 - acc: 0.8112 - val_loss: 0.0160 - val_acc: 0.8096\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 29s - loss: 0.0153 - acc: 0.8114 - val_loss: 0.0152 - val_acc: 0.8089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120e923d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We almost get 81 percent accuracy.Which is pretty good.\n",
    "model.fit(X_train, X_train,\n",
    "         epochs=10,\n",
    "         shuffle=True,\n",
    "        batch_size=100,\n",
    "         validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32)\n"
     ]
    }
   ],
   "source": [
    "#Seeing how well does the encoder work for first 100 examples\n",
    "enc_out = encoder.predict(X_train[:100])\n",
    "print enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Putting the output of encoder in the decoder to recreate those images .\n",
    "rec = decoder.predict(enc_out)\n",
    "print rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaL+HxOC461dANrsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1215e6510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRRl+qSjDLxVl+KWi/h/lFeMIzEtueAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1215ba2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx = 15\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(X_train[nx].reshape((28, 28)), cmap='gray')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(rec[nx].reshape((28, 28)), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
